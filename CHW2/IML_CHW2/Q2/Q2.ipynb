{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChC3RF8meAlK"
      },
      "source": [
        "<h1 align=\"center\">Introduction to Machine Learning - 25737-2</h1>\n",
        "<h4 align=\"center\">Dr. R. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
        "\n",
        "\n",
        "**<font color='red'>Plagiarism is strongly prohibited!</font>**\n",
        "\n",
        "\n",
        "**Student Name**: Ehsan Merrikhi\n",
        "\n",
        "**Student ID**: 400101967\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IraiR0SbeDi_"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRQjwWC3eDnc"
      },
      "source": [
        "**Task:** Implement your own Logistic Regression model, and test it on the given dataset of Logistic_question.csv!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MyLogisticRegression:\n",
        "\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(z):\n",
        "        nom = 1\n",
        "        denom = 1 + np.exp(-z)\n",
        "        return nom / denom\n",
        "\n",
        "    @staticmethod\n",
        "    def loss_function(y, y_pred):\n",
        "        log_loss = np.mean(-y * np.log(y_pred) -(1-y) * np.log(1-y_pred))\n",
        "        return log_loss\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_pred = MyLogisticRegression.sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / X.shape[0]) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / X.shape[0]) * np.sum(y_pred - y)\n",
        "\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_pred = MyLogisticRegression.sigmoid(linear_model)\n",
        "        return np.round(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-i-oubUlZ6e"
      },
      "source": [
        "**Task:** Test your model on the given dataset. You must split your data into train and test, with a 0.2 split, then normalize your data using X_train data. Finally, report 4 different evaluation metrics of the model on the test set. (You might want to first make the Target column binary!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KXzIy_2u-pG",
        "outputId": "9625f7e2-abb1-4591-c0fa-843525e0ffd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.850000\n",
            "Precision: 0.850000\n",
            "Recall: 1.000000\n",
            "F1-score: 0.918919\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here!\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# get data\n",
        "data = pd.read_csv('Logistic_question.csv')\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "y = (y > 0.5)\n",
        "\n",
        "# split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=67)\n",
        "\n",
        "# normalize\n",
        "scaler = StandardScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "# do office work\n",
        "model = MyLogisticRegression()\n",
        "model.fit(X_train_norm, y_train)\n",
        "y_pred = model.predict(X_test_norm)\n",
        "\n",
        "# how good was my accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# doesn't seem bad\n",
        "print(f\"Accuracy: {accuracy:.6f}\")\n",
        "print(f\"Precision: {precision:.6f}\")\n",
        "print(f\"Recall: {recall:.6f}\")\n",
        "print(f\"F1-score: {f1:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji0RXNGKv1pa"
      },
      "source": [
        "**Question:** What are each of your used evaluation metrics? And for each one, mention situations in which they convey more data on the model performance in specific tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldveD35twRRZ"
      },
      "source": [
        "*Accuracy:* accuracy shows the proportion of right predictions out of total predictions. It shows how good the model works in general.\n",
        "\n",
        "*Precision:* precision shows the proportion of true positive predictions out of the total positive predictions. Precision is important when the cost of a false positive is high.\n",
        "\n",
        "*Recall:* recall shows the proportion of true positive predictions out of the total positive instances. Recall is important when the cost of a false negative is high.\n",
        "\n",
        "*F1-score:* The mean of precision and recall, The F1-score is useful when you want to have a single metric that captures both precision and recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZCeRHZSw-mh"
      },
      "source": [
        "**Task:** Now test the built-in function of Python for Logistic Regression, and report all the same metrics used before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vb5lRSQXDLR3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.900000\n",
            "Precision: 0.894737\n",
            "Recall: 1.000000\n",
            "F1-score: 0.944444\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "data = pd.read_csv('Logistic_question.csv')\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "y = (y > 0.5)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=67)\n",
        "\n",
        "# normalize\n",
        "scaler = StandardScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "# do office work\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_norm, y_train)\n",
        "y_pred = model.predict(X_test_norm)\n",
        "\n",
        "# how good was my accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# doesn't seem bad\n",
        "print(f\"Accuracy: {accuracy:.6f}\")\n",
        "print(f\"Precision: {precision:.6f}\")\n",
        "print(f\"Recall: {recall:.6f}\")\n",
        "print(f\"F1-score: {f1:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCvIymmMy_ji"
      },
      "source": [
        "**Question:** Compare your function with the built-in function. On the matters of performance and parameters. Briefly explain what the parameters of the built-in function are and how they affect the model's performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY0ohM16z3De"
      },
      "source": [
        "*My code metrics report:* \n",
        "\n",
        "Accuracy: 0.850000 \n",
        "\n",
        "Precision: 0.850000 \n",
        "\n",
        "Recall: 1.000000 \n",
        "\n",
        "F1-score: 0.918919 \n",
        "\n",
        "*Built in library metrics report:* \n",
        "Accuracy: 0.900000 \n",
        "\n",
        "Precision: 0.894737\n",
        "\n",
        "Recall: 1.000000\n",
        "\n",
        "F1-score: 0.944444\n",
        "\n",
        "\n",
        "we see in every aspect the built in model was better than mine.\n",
        "\n",
        "also the execution time for my model was higher than the sklearn library.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClMqoYlr2kr7"
      },
      "source": [
        "# Multinomial Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukvlqDe52xP5"
      },
      "source": [
        "**Task:** Implement your own Multinomial Logistic Regression model. Your model must be able to handle any number of labels!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5Ir-_hFt286t",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MyMultinomialLogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=100, lambda_=0.1):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.lambda_ = lambda_\n",
        "        self.theta = None\n",
        "        self.num_classes = None\n",
        "\n",
        "    def softmax(self, z):\n",
        "        exp_scores = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m, n = X.shape\n",
        "        self.num_classes = len(np.unique(y))\n",
        "        self.theta = np.zeros((n + 1, self.num_classes))\n",
        "\n",
        "        # Add a column of ones to X for bias term\n",
        "        X_bias = np.hstack((X, np.ones((m, 1))))\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            # Forward pass\n",
        "            linear_model = np.dot(X_bias, self.theta)\n",
        "            y_pred = self.softmax(linear_model)\n",
        "\n",
        "            # Compute gradients\n",
        "            one_hot_y = np.eye(self.num_classes)[y]\n",
        "            error = y_pred - one_hot_y\n",
        "            gradient = np.dot(X_bias.T, error) / m\n",
        "\n",
        "            # Update parameters\n",
        "            self.theta -= self.learning_rate * gradient\n",
        "\n",
        "    def predict_probability(self, X):\n",
        "        # Add a column of ones to X for bias term\n",
        "        X_bias = np.hstack((X, np.ones((X.shape[0], 1))))\n",
        "        scores = np.dot(X_bias, self.theta)\n",
        "        return self.softmax(scores)\n",
        "\n",
        "    def predict(self, X):\n",
        "        probabilities = self.predict_probability(X)\n",
        "        return np.argmax(probabilities, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPQ3Rtay3Y2_"
      },
      "source": [
        "**Task:** Test your model on the given dataset. Do the same as the previous part, but here you might want to first make the Target column quantized into $i$ levels. Change $i$ from 2 to 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9aP4QJPq29B3",
        "metadata": {}
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'MyLogisticRegression' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m X_test_norm \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# do office work\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyLogisticRegression\u001b[49m(i)\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_norm, y_train)\n\u001b[0;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_norm)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'MyLogisticRegression' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = pd.read_csv('Logistic_question.csv')\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "\n",
        "i = 4\n",
        "bins = np.linspace(0, 1, i)\n",
        "y = np.digitize(y, bins)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=67)\n",
        "# normalize\n",
        "scaler = StandardScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "# do office work\n",
        "model = MyMultinomialLogisticRegression(i)\n",
        "model.fit(X_train_norm, y_train)\n",
        "y_pred = model.predict(X_test_norm)\n",
        "print(y_pred)\n",
        "# how good was my accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "# doesn't seem bad\n",
        "print(f\"Accuracy: {accuracy:.6f}\")\n",
        "print(f\"Precision: {precision:.6f}\")\n",
        "print(f\"Recall: {recall:.6f}\")\n",
        "print(f\"F1-score: {f1:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of2sHl5Z4dXi"
      },
      "source": [
        "**Question:** Report for which $i$ your model performs best. Describe and analyze the results! You could use visualizations or any other method!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRLERDAr4wnS"
      },
      "source": [
        "**Your answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT43jGKV6CBZ"
      },
      "source": [
        "# Going a little further!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo9uGo0R6GZo"
      },
      "source": [
        "First we download Adult income dataset from Kaggle! In order to do this create an account on this website, and create an API. A file named kaggle.json will be downloaded to your device. Then use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "o-vrjYBF7u1E",
        "metadata": {},
        "outputId": "b274bc6e-4c35-4ad8-f17b-9e69f7d92923"
      },
      "outputs": [],
      "source": [
        "from google.colab import files \n",
        "files.upload()  # Use this to select the kaggle.json file from your computer\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i6u6_1v8ftX"
      },
      "source": [
        "Then use this code to automatically download the dataset into Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjyVaVKF29Hx",
        "outputId": "15d0b1a2-c806-4102-abbc-12545237e218"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d wenruliu/adult-income-dataset\n",
        "!unzip /content/adult-income-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXQnbZwt8rJK"
      },
      "source": [
        "**Task:** Determine the number of null entries!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtuEx6QW29c1",
        "metadata": {},
        "outputId": "43397bec-0622-4dc4-de2b-c65be00e4503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6465\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here!\n",
        "\n",
        "import pandas as pd\n",
        "# null entries in the dataset are filled with \"?\"\n",
        "# we need to find how many \"?\" we have\n",
        "data = pd.read_csv('adult.csv')\n",
        "data.replace('?', pd.NA, inplace=True)\n",
        "null_count = data.isnull().sum().sum()\n",
        "\n",
        "print(null_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpEcBdTUAYVN"
      },
      "source": [
        "**Question:** In many widely used datasets there are a lot of null entries. Propose 5 methods by which, one could deal with this problem. Briefly explain how do you decide which one to use in this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1u1pBHuAsSg"
      },
      "source": [
        "**Your answer:**\n",
        "\n",
        "*1:*\n",
        "we can delete all the rows that have at least one null entry.\n",
        "\n",
        "*2:*\n",
        "we can replace null entries with median or mode or mean of other valid values.\n",
        "\n",
        "*3:*\n",
        "we can also use machine learning methods to predict the value which is missing.\n",
        "\n",
        "*4:*\n",
        "if null entries could contain information we can also use them as valid values.\n",
        "\n",
        "*5:*\n",
        "there are algorithms that support missing values so we can use them instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHhH-hkpAxFf"
      },
      "source": [
        "**Task:** Handle null entries using your best method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5fVwWcjK29fk",
        "metadata": {},
        "outputId": "c21a6adf-1e6c-46d0-dd61-79d1710272c1"
      },
      "outputs": [],
      "source": [
        "# Your code goes here!\n",
        "# decided to replace NA values with mode of column\n",
        "for column in data.columns:\n",
        "    mode_value = data[column].mode()[0]\n",
        "    data[column].fillna(mode_value, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43k5cTorCJaV"
      },
      "source": [
        "**Task:** Convert categorical features to numerical values. Split the dataset with 80-20 portion. Normalize all the data using X_train. Use the built-in Logistic Regression function and GridSearchCV to train your model, and report the parameters, train and test accuracy of the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agj18Lcd-vyZ",
        "metadata": {},
        "outputId": "69e132a9-0249-4a21-c8f3-45247c1e17dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_param: {'C': 1, 'max_iter': 200, 'solver': 'saga'}\n",
            "Train Accuracy: 82.4406%\n",
            "Test Accuracy: 82.8437%\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here!\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    data[column] = label_encoder.fit_transform(data[column].astype(str))\n",
        "X = data.drop('income', axis=1)\n",
        "Y = data['income']\n",
        "# print(data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=67)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(data.shape)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "log_reg_model = LogisticRegression()\n",
        "log_reg_model.fit(X=X_train_norm, y=y_train)\n",
        "y_pred_log = log_reg_model.predict(X_test_norm)\n",
        "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
        "param_log = log_reg_model.coef_\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  \n",
        "    'solver': ['liblinear', 'lbfgs', 'sag', 'saga'],  \n",
        "    'max_iter': [100, 200, 300]  \n",
        "}\n",
        "\n",
        "grid_search_model = GridSearchCV(LogisticRegression(), param_grid=param_grid)\n",
        "grid_search_model.fit(X_train_norm, y_train)\n",
        "\n",
        "best_param = grid_search_model.best_params_\n",
        "best_model = grid_search_model.best_estimator_\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, best_model.predict(X_train_norm))\n",
        "test_accuracy = accuracy_score(y_test, best_model.predict(X_test_norm))\n",
        "\n",
        "print(f'best_param: {best_param}')\n",
        "print(f'Train Accuracy: {100 * train_accuracy:.4f}%')\n",
        "print(f'Test Accuracy: {100 * test_accuracy:.4f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lzr2lqXDQ1T"
      },
      "source": [
        "**Task:** To try a different route, split X_train into $i$ parts, and train $i$ separate models on these parts. Now propose and implement 3 different *ensemble methods* to derive the global models' prediction for X_test using the results(not necessarily predictions!) of the $i$ models. Firstly, set $i=10$ to find the method with the best test accuracy(the answer is not general!). You must Use your own Logistic Regression model.(You might want to modify it a little bit for this part!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9D1jlstF9nF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QS9HYJ5FW1T"
      },
      "source": [
        "**Question:** Explain your proposed methods and the reason you decided to use them!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hCBQuAeF46a"
      },
      "source": [
        "**Your answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjSREvg4FTHf"
      },
      "source": [
        "**Task:** Now, for your best method, change $i$ from 2 to 100 and report $i$, train and test accuracy of the best model. Also, plot test and train accuracy for $2\\leq i\\leq100$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfKS-Jq0-v4P"
      },
      "outputs": [],
      "source": [
        "# Your code goes here!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWV0YUgRGg1p"
      },
      "source": [
        "**Question:** Analyze the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer:**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
